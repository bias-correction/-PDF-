import streamlit as st
from langchain.memory import ConversationBufferMemory
from utils import qa_agent

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(
                            return_messages=True,
                            memory_key='chat_history',
                            output_key='answer')
    st.session_state["messages"] = []

st.title("ðŸ“‘ AIæ™ºèƒ½PDFé—®ç­”å·¥å…·")

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥OpenAI APIå¯†é’¥ï¼š", type="password")
    st.markdown("[èŽ·å–OpenAI API key](https://platform.openai.com/account/api-keys)")

uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type=['pdf'])
question = st.text_input("å¯¹PDFçš„å†…å®¹è¿›è¡Œæé—®", disabled=not uploaded_file)
submit = st.button("æäº¤")

if submit:
    if not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„OpenAI API Key")
        st.stop()
    if not question:
        st.info("è¯·è¾“å…¥æé—®çš„é—®é¢˜")
        st.stop()

    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        result = qa_agent(openai_api_key,
                      st.session_state["memory"],
                      uploaded_file, question)
        st.write("### ç­”æ¡ˆ")
        st.write(result['answer'])
        st.session_state["messages"].append({"question": question, "answer": result['answer']})

        with st.expander("åŽ†å²æ¶ˆæ¯"):
            for (index, msg) in enumerate(st.session_state["messages"]):
                if index > 0:
                    st.divider()
                st.chat_message("human").write(msg["question"])
                st.chat_message("ai").write(msg["answer"])

